# main.py
# python main.py --workers 6

import argparse
import logging
import os
from datetime import datetime
import numpy as np
import random
import pandas as pd
from scipy.stats import ttest_rel, wilcoxon

from config import GLOBAL_SEED, SIMULATION_CONFIG
from utils import setup_logging
from simulation import run_parallel_simulations
from reporting import generate_reports
from slack_notifier import send_slack_message




# ==========================================================
# ğŸ“Š Mixed vs Logit ã®çµ±è¨ˆçš„æœ‰æ„å·®æ¤œå®šé–¢æ•°
# ==========================================================
def compare_mixed_logit_significance(df: pd.DataFrame, output_dir: str):
    """
    precision / recall / f1 ã® Mixed vs Logit ã‚’å¯¾å¿œã®ã‚ã‚‹ tæ¤œå®šãƒ»Wilcoxonæ¤œå®šã§æ¯”è¼ƒ
    """
    results = []
    metrics = ["precision", "recall", "f1_score"]

    for metric in metrics:
        col_m = f"{metric}_mixed"
        col_l = f"{metric}_logit"
        if col_m not in df.columns or col_l not in df.columns:
            logging.warning(f"{metric}: åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ (skip)")
            continue

        x = df[col_m].values
        y = df[col_l].values
        mask = np.isfinite(x) & np.isfinite(y)
        x, y = x[mask], y[mask]

        if len(x) < 5:
            logging.warning(f"{metric}: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ ({len(x)} ãƒšã‚¢)")
            continue

        # --- å¯¾å¿œã®ã‚ã‚‹æ¤œå®š (ç‰‡å´: logit > mixed) ---
        t_stat, t_p = ttest_rel(y, x, alternative='greater')
        try:
            w_stat, w_p = wilcoxon(y - x, alternative='greater')
        except ValueError:
            w_stat, w_p = np.nan, np.nan

        mean_diff = np.mean(y - x)
        better = "logit > mixed" if mean_diff > 0 else "mixed > logit"

        results.append({
            "Metric": metric.upper(),
            "Mean(Mixed)": np.mean(x),
            "Mean(Logit)": np.mean(y),
            "MeanDiff(Logit-Mixed)": mean_diff,
            "Better": better,
            "t_pval": t_p,
            "wilcoxon_pval": w_p
        })

    # --- å‡ºåŠ› ---
    res_df = pd.DataFrame(results)
    out_path = os.path.join(output_dir, "significance_mixed_logit.csv")
    res_df.to_csv(out_path, index=False, float_format="%.6f")

    logging.info(f"æœ‰æ„å·®æ¤œå®šçµæœã‚’ä¿å­˜: {out_path}")
    send_slack_message(f"ğŸ“Š Mixed vs Logit æœ‰æ„å·®æ¤œå®šå®Œäº†\nçµæœ: `{os.path.basename(out_path)}`")
    logging.info(f"\n{res_df}\n")

    # Slackã«ã‚‚çµæœã‚’æ¦‚è¦ã§é€šçŸ¥
    summary_lines = [
        f"{r['Metric']}: t_p={r['t_pval']:.4f}, w_p={r['wilcoxon_pval']:.4f}, better={r['Better']}"
        for _, r in res_df.iterrows()
    ]
    send_slack_message("```\n" + "\n".join(summary_lines) + "\n```")

    return res_df


# ==========================================================
# ğŸ¯ ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
# ==========================================================
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--output_dir", type=str, default="results", help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--workers", type=int, default=os.cpu_count(), help="ä¸¦åˆ—å®Ÿè¡Œæ•°")
    args = parser.parse_args()

    os.makedirs(args.output_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    np.random.seed(GLOBAL_SEED)
    random.seed(GLOBAL_SEED)

    config = SIMULATION_CONFIG
    simulation_seeds = [np.random.randint(0, 2**31 - 1) for _ in range(config["N_SIMULATIONS"])]

    param_str = (
        f"sim{config['N_SIMULATIONS']}_s{config['N_SAMPLES']}_"
        f"l{config['LAG']}_v{config['N_VARS']}_bs{config['BOOTSTRAP_SAMPLES']}"
    )
    # --- configä¿å­˜ ---
    import json
    with open(os.path.join(args.output_dir, f"config_{timestamp}.json"), "w") as f:
        json.dump(config, f, indent=2)

    logging.info(f"é–‹å§‹: {config['N_SIMULATIONS']} å›ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ {args.workers} ä¸¦åˆ—ã§å®Ÿè¡Œã—ã¾ã™")
    logging.info(f"è¨­å®š: {config}")
    send_slack_message(f"ğŸš€ main.py å®Ÿè¡Œé–‹å§‹\nè¨­å®š: {config}\nWorkers={args.workers}")

    try:
        results_all, summary_counts = run_parallel_simulations(config, args.workers, simulation_seeds)

        # --- ãƒ­ã‚°ã‚µãƒãƒª ---
        n_total = config["N_SIMULATIONS"]
        n_completed = (
            summary_counts.get("success", 0)
            + summary_counts.get("partial", 0)
            + summary_counts.get("empty_success", 0)
            + summary_counts.get("internal_error", 0)
        )
        n_failed = summary_counts.get("timeout", 0) + summary_counts.get("pool_error", 0)
        n_processed = n_completed + n_failed

        logging.info(f"--- ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œã‚µãƒãƒª (å‡¦ç†æ¸ˆ: {n_processed} / {n_total}) ---")
        logging.info(f"  [å®Œäº†] {n_completed} å› (ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãªã—)")
        logging.info(f"    - æˆåŠŸ (å…¨è¡Œ): {summary_counts.get('success', 0)} å›")
        logging.info(f"    - éƒ¨åˆ†æˆåŠŸ: {summary_counts.get('partial', 0)} å›")
        logging.info(f"    - LiNGAMå¤±æ•—: {summary_counts.get('empty_success', 0)} å›")
        logging.info(f"    - å†…éƒ¨ã‚¨ãƒ©ãƒ¼: {summary_counts.get('internal_error', 0)} å›")
        logging.info(f"  [å¤±æ•—] {n_failed} å›")
        logging.info(f"    - ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {summary_counts.get('timeout', 0)} å›")
        logging.info(f"    - ãƒ—ãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼: {summary_counts.get('pool_error', 0)} å›")
        logging.info(f"--- åˆè¨ˆåé›†çµæœ (ç·è¡Œæ•°): {len(results_all)} ---")

        if not results_all:
            msg = "âš ï¸ çµæœãŒç©ºã§ã™ã€‚VAR-LiNGAMãŒã™ã¹ã¦å¤±æ•—ã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
            logging.warning(msg)
            send_slack_message(msg)
            return

        # --- ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ ---
        generate_reports(
            results_all=results_all,
            output_dir=args.output_dir,
            param_str=param_str,
            timestamp=timestamp,
            n_simulations=config["N_SIMULATIONS"],
            config=config
        )

        # --- æœ‰æ„å·®æ¤œå®šã®å®Ÿè¡Œ ---
        df_results = pd.DataFrame(results_all)

        # ç¸¦å‹ãƒ‡ãƒ¼ã‚¿ã‚’æ¨ªå‹ï¼ˆmixed/logitåˆ—ï¼‰ã«å¤‰æ›
        df_wide = (
            df_results.pivot_table(
                index=df_results.index // 3,  # sim_idãŒãªã„å ´åˆã€ãƒ–ãƒ­ãƒƒã‚¯ã”ã¨ã«ã¾ã¨ã‚ã‚‹
                columns="sim_type",
                values=["precision", "recall", "f1_score"]
            )
        )
        df_wide.columns = [f"{m}_{t.lower()}" for m, t in df_wide.columns]
        df_wide.reset_index(drop=True, inplace=True)

        # ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆ: df_wideã‚’ãƒã‚§ãƒƒã‚¯ãƒ»æ¸¡ã™
        # --- åˆ—åã‚’æ­£è¦åŒ–ã—ã¦å­˜åœ¨ãƒã‚§ãƒƒã‚¯ ---
        df_wide.rename(columns=lambda c: c.lower().replace("logitscore", "logit"), inplace=True)
        if all(f"{m}_mixed" in df_wide.columns and f"{m}_logit" in df_wide.columns for m in ["precision", "recall", "f1_score"]):
            compare_mixed_logit_significance(df_wide, args.output_dir)
        else:
            logging.warning("Mixed/Logitåˆ—ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚æ¤œå®šã‚’ã‚¹ã‚­ãƒƒãƒ—")

        try:
            send_slack_message(f"âœ… main.py å®Ÿè¡Œå®Œäº†: {config['N_SIMULATIONS']} å›ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†")
        except Exception as e:
            logging.error(f"Slacké€šçŸ¥å¤±æ•—: {e}")
        logging.info("Precision / Recall / F1 ã®æœ‰æ„å·®æ¤œå®šã‚’å«ã‚€å…¨å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

    except Exception as e:
        logging.error(f"main.py å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        send_slack_message(f"ğŸ’¥ main.py å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")


if __name__ == "__main__":
    main()
